archived: false
status: "Available"
category: Bachelor Thesis Projects 2024-25
is_group: false
keywords:
- software architecture
- LLM
- ML
posted: 2025-01-07
description: Investigate the role of fine-tuning large language models in improving predictions related to software architecture decisions, combining empirical analysis and machine learning techniques.
contact:
  header: Supervisor(s)
  members:
  - s.k.pandey@rug.nl
title: Fine-Tuning Large Language Models for Software Architecture Decision Support: An Empirical Study
types:
- BSc
---

Large language models (LLMs) such as GPT and RoBERTa have shown promise in natural language processing tasks, but their role in supporting software architecture decisions remains underexplored. This project aims to:

1. **Fine-Tuning**: Fine-tune an LLM on datasets related to software architecture decisions, including design patterns, architectural trade-offs, and system quality attributes.
2. **Empirical Analysis**: Conduct experiments to measure the effectiveness of the fine-tuned model in predicting architecture decisions, identifying potential improvements, and supporting automated decision-making.
3. **Machine Learning Integration**: Investigate how LLMs can work alongside traditional ML models to provide a hybrid approach to analyzing software architecture data.

This study will provide insights into:
- The effectiveness of fine-tuning for software architecture tasks.
- Empirical benchmarks on real-world datasets to evaluate model performance.
- Practical implications for integrating LLMs into architecture decision-making pipelines.

### Pointers to literature
[1] Nashaat, Mona, and James Miller. "Towards efficient fine-tuning of language models with organizational data for automated software review." IEEE Transactions on Software Engineering (2024).
[2] Hou, Xinyi, et al. "Large language models for software engineering: A systematic literature review." ACM Transactions on Software Engineering and Methodology 33.8 (2024): 1-79.
